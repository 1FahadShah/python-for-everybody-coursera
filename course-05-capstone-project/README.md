# ğŸš€ **Course 05 â€“ Capstone Project**

## ğŸ§  KRAWLIX â€” Knowledge Crawler

KRAWLIX is a command-line knowledge extraction tool that fetches topic summaries from public sources like **DuckDuckGo** and **Wikipedia**, then stores them in both a local SQLite database and as `.txt` files.  
Designed entirely with **Python Standard Library only**, this is a real-world, **Portfolio Ready** capstone project built to demonstrate practical Python, API integration, and structured data storage.

---

## ğŸš€ Why I Built This

As part of my **Python for Everybody** specialization capstone, I wanted to go beyond toy problems and build a real, modular, CLI-based tool that:

- âœ… Integrates public APIs  
- âœ… Handles failures gracefully  
- âœ… Stores structured data  
- âœ… Uses zero external libraries  
- âœ… Feels like the base layer of a real AI assistant  

> This is **KRAWLIX** â€” a production-grade CLI tool that showcases my ability to design structured, scalable systems at the intersection of Python, data, and infrastructure.

---

## ğŸ§  Features

- ğŸ” **Smart Fetching System**  
  - DuckDuckGo Instant Answer API (primary source)  
  - Wikipedia REST API (fallback if DuckDuckGo fails)

- ğŸ’¡ **Built-in Stability Layer**  
  - Gracefully handles failed requests with structured `try-except` blocks  
  - Automatically switches to Wikipedia if DuckDuckGo returns empty  
  - Logs unresolved topics to `failed_topics.txt` for debugging

- ğŸ—ƒ **Dual Output Storage**  
  - Structured entries into SQLite (`db/krawlix.sqlite`)  
  - Plaintext `.txt` files saved in `summaries/` folder

- ğŸ§± **Zero Dependency Architecture**  
  - Built using only: `urllib`, `json`, `sqlite3`, `os`, `sys`, `datetime`  
  - Fully modular design with clean separation of logic

- ğŸ–¥ **CLI Native**  
  - Accepts topic list via `data/topics.txt`  
  - Executed via `python main.py <file_path>`  
  - Minimal setup, fully local, cross-platform


---

## ğŸ¥ Demo

![Krawlix CLI Demo](demo/krawlix-demo.gif)

> This CLI tool fetches structured summaries via DuckDuckGo/Wikipedia and stores them in both `.txt` and `.sqlite` formats â€” using only Python Standard Library.


## ğŸ›  Tech Stack


| Layer      | Tool                                |
| ---------- | ----------------------------------- |
| Language   | Python 3 (Standard Library Only)    |
| Storage    | SQLite3, File I/O (`.txt`)          |
| APIs       | DuckDuckGo, Wikipedia REST          |
| Interface  | CLI (`python main.py <topics.txt>`) |
| OS Tested  | Windows 11 + Python 3.11            |
| Versioning | Git + GitHub                        |


  
---

## ğŸ“‚ Folder Contents

```bash
course-05-capstone-krawlix/
â”œâ”€â”€ crawler/                     # API fetching, DB writing, utility modules
â”‚   â”œâ”€â”€ fetch.py
â”‚   â”œâ”€â”€ db_writer.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ data/                        # Input topic list
â”‚   â””â”€â”€ topics.txt
â”œâ”€â”€ db/                          # SQLite database
â”‚   â””â”€â”€ krawlix.sqlite
â”œâ”€â”€ demo/                        # Demo GIF and visuals
â”‚   â””â”€â”€ krawlix-demo.gif
â”œâ”€â”€ export/                      # (Optional) Export features (reserved)
â”œâ”€â”€ summaries/                   # Saved topic summaries as text files
â”‚   â””â”€â”€ <topic>.txt
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ failed_topics.txt            # Log of topics not found
â”œâ”€â”€ main.py                      # CLI entry point
â”œâ”€â”€ requirements.txt             # Empty (used for environment consistency)
â”œâ”€â”€ test.py                      # Manual test runner

```

---

## ğŸ› ï¸ How It Works

### Step 1: Add topics to `data/topics.txt`

```text
Python programming
Artificial Intelligence
Generative AI
```

### Step 2: Run the crawler

```bash
python main.py data/topics.txt
```

### Step 3: Output

```text
summaries/Python_programming.txt        âœ”ï¸
summaries/Artificial_Intelligence.txt   âœ”ï¸
failed_topics.txt â†’ NonexistentTopic123 âŒ
```

---

## ğŸ“Š What This Project Proves

* End-to-end knowledge ingestion using legal public APIs
* Clean code separation across modules
* Text + database storage via `sqlite3` and file I/O
* Scalable system design
* CLI-based tool thinking aligned with Automation Engineering

---


## ğŸ“ Notes

* This is a **true capstone**: designed, written, and tested independently.
* The architecture is intentionally clean, but extensible.
* Future versions can add Markdown export, CLI arguments, or integration into RAG pipelines.

> ğŸ§  This project demonstrates how clean scripting, modular thinking, and public APIs can produce production-grade tools â€” even within constraints.

---

## ğŸŒ Connect with Me

* [LinkedIn](https://linkedin.com/in/1fahadshah)
* [GitHub](https://github.com/1fahadshah)
* [Medium](https://medium.com/@1fahadshah)
* [X / Twitter](https://twitter.com/1fahadshah)



> ğŸ“Œ This project aligns with my long-term path in Python â€” from automation to AI Systems.  
> *I build tools that scale knowledge, not just code.* â€” **1FahadShah**

